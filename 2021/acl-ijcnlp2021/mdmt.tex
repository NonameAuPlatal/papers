%
% File acl2021.tex
%
%% Based on the style files for EMNLP 2020, which were
%% Based on the style files for ACL 2020, which were
%% Based on the style files for ACL 2018, NAACL 2018/19, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2021}
\usepackage{times}
\usepackage{latexsym}
\renewcommand{\UrlFont}{\ttfamily\small}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B\textsc{ib}\TeX}

% Standard package includes
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{longtable}
\usepackage{tikz}
\usetikzlibrary{calc}
\usepackage[draft]{todo}
\usepackage[normalem]{ulem}
\usepackage{xspace}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{algorithm, algorithmic}
\newcommand{\fyTodo}[1]{\Todo[FY:]{\textcolor{orange}{#1}}}
\newcommand{\fyTodostar}[1]{\Todo*[FY:]{\textcolor{orange}{#1}}}
\newcommand{\fyDone}[1]{\done[FY]\Todo[FY:]{\textcolor{orange}{#1}}}
\newcommand{\fyFuture}[1]{\done[FY]\Todo[FY:]{\textcolor{red}{#1}}}
\newcommand{\fyDonestar}[1]{\done[FY]\Todo[FY:]{\textcolor{orange}{#1}}}
\newcommand{\revision}[1]{#1}
\newcommand{\revisiondel}[1]{}
\newcommand{\src}{\ensuremath{\mathbf{f}}} % source sentence
\newcommand{\trg}{\ensuremath{\mathbf{e}}} % target sentence
\newcommand{\domain}[1]{\texttt{\textsc{#1}}}
\newcommand{\system}[1]{\texttt{{#1}}}
\newcommand{\vlambda}{\ensuremath{\boldsymbol\lambda}\xspace} % parameters vector for a distribution
\newcommand{\indic}[1]{\ensuremath{\mathbb{I}(#1)}}
% \newcommand{\SB}[1]{\textcolor{green}{#1}}
% \newcommand{\SW}[1]{\textcolor{red}{#1}}
\newcommand{\SB}[1]{\textbf{#1}}
\newcommand{\SW}[1]{\underline{#1}}
\renewcommand\textfraction{.1}
\renewcommand\floatpagefraction{.95}
\newcommand{\sbcl}[2]{{\scriptsize #1 \hfill $|$ \hfill  #2}}
\usepackage{multirow}


\title{Improving Multi-Domain Neural Machine Translation by Differential Data Selection}

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
  When building machine translation systems, one often needs to make the best out of heterogeneous sets of parallel data in training to achieve the best test performance in one or several domain(s) of interest. This multi-source (multi-domain) adaptation problem is often approach with instance selection or reweighting strategies, most of which pre-supposes an ad-hoc assessment of relevance for training sentences. In this contribution, we study the recently proposed Differential Data Selection (DDS) model  and explore its ability to serve an effective generic framework for these various situations. Our experiments for both domain adaptation and multi-domain learning show that DDS often enables to outperform heuristic training strategy; we also introduce a variant that boosts DDS performance in the presence of adapter modules. 
%   This is a well-known issue, which has given raise to a rich litterature in under the umbrellas of domain adaptation or multi-domain 

%   The priority of the in-domain performance in the overall evaluation affects the choice of choosing data. The problem falls in the data selection category in the domain adaptation topic. Several data selection methods pre-compute the domain-relatedness of training examples and use these scores to build mini-batches in the training while other works propose dynamic strategies to build training mini-batches based on reinforcement learning.
% In this study, we first formulate the most general algorithm for training the Neural Machine Translation (NMT) model given a predefined priority of the domains. Then, we apply a recently proposed method to solve the problem. We also report a disadvantage of DDS and fix it by proposing a minor development for DDS. Our experiments with a large sample of multi-domain systems show several important benefits of DDS in multi-domain NMT.
\end{abstract}

\section{Introduction}\label{sec:intro}

\section{Formalizing multi-domain translation}
\begin{algorithm}[h!]
\caption{Multi-domain Training} \label{alg:mdmt}
\label{alg:multidomain}
\begin{algorithmic}[1]
\REQUIRE {
\begin{itemize}
	\item Corpora $C^i, i\in [1,..,K]$ for $K$ domains.
	\item Dev sets $Dev^i, i\in [1,..,K]$ for $K$ domains.
	\item Importance weights of domains in the final evaluation $\lambda_{t,d}^i, i\in [1,..,K]$
	\item Batch size $B$.
	\item Temporal Data Selection Distribution(T-DSD)$$P_{\system{T-DSD}}(t)(x,y)=\sum_{i}\lambda_{l,d}^i(t)P_i(t)(x,y)$$
	\item $Eval\_scores = []$
	\item $Early\_stopping$ criterion.
\end{itemize}}
\REPEAT 
\STATE{Iteration t.}
\STATE{Randomly pick $i \in [1,..,K]$ w.r.t  $[\lambda_{l,d}^1 \dots \lambda_{l,d}^K](t)$.}
\STATE{Sample $B$ sentences from $C^i$ with empirical distribution $P_i(t)(x,y)$.}
\STATE{Update model by applying SGD computed from $B$ sampled sentences.}
\IF{$t \equiv 0 \mod{eval\_step}$}
	\STATE{Evaluate current model with K dev sets. Denote $S_t^i$ performance of model at iteration t on domain i.}
	\STATE{Report weighted score using Domain Importance Weights(DI-Weights) $\lambda_{t,d}^i, i\in [1,..,K]$. $$eval(t) = \displaystyle{\mathop{\sum}_i \lambda_{t,d}^i S_t^i}$$}
	\STATE{$Eval\_scores.append(eval(t))$.}
\ENDIF
\IF{$Early\_stopping(Eval\_scores)$}
	\STATE{Stop training loop.}
\ENDIF
\UNTIL{convergence}
\end{algorithmic}
\end{algorithm}
\section*{Acknowledgments}
\bibliographystyle{acl_natbib}
\bibliography{multidomain}
%\appendix
\end{document}
